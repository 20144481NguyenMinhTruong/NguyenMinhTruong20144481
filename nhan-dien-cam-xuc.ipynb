{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization, LSTM\nfrom keras.models import Sequential \nfrom tensorflow.keras.utils import to_categorical\nfrom keras import callbacks\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n# from keras.optimizers import Adam\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers import Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nimport cv2\nimport cv2 as cv\nfrom sklearn.model_selection import train_test_split\nimport pickle\nimport os\nimport pandas as pd\nimport random\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop # toi uu\nfrom keras.models import Sequential\nfrom keras.layers import Dense # fully connected\nfrom keras.datasets import boston_housing\nfrom tensorflow.keras.optimizers import RMSprop # toi uu\nfrom keras.callbacks import EarlyStopping # dung lai ngay lap tuc\nfrom sklearn.preprocessing import scale # xu li du lieu","metadata":{"_uuid":"e17be440-31c7-4e8f-801c-6c521183eb6e","_cell_guid":"655d4189-ee19-4dd7-a06b-b184248423ab","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:55:51.647727Z","iopub.execute_input":"2022-12-06T08:55:51.648088Z","iopub.status.idle":"2022-12-06T08:55:51.659361Z","shell.execute_reply.started":"2022-12-06T08:55:51.648062Z","shell.execute_reply":"2022-12-06T08:55:51.658016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize path\npath = \"/kaggle/input/truong-20144481/emotion_smalldata/emotion_smalldata/train_class\"","metadata":{"_uuid":"f65a726e-d868-4edc-be58-74b40a553200","_cell_guid":"b9eecf18-079c-4640-9c95-9222040e0b97","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:55:58.739217Z","iopub.execute_input":"2022-12-06T08:55:58.740543Z","iopub.status.idle":"2022-12-06T08:55:58.748491Z","shell.execute_reply.started":"2022-12-06T08:55:58.740455Z","shell.execute_reply":"2022-12-06T08:55:58.746240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\ncount = 0\nimages = []\nclassNo = []\nmyList = os.listdir(path)\nprint(\"Total Classes Detected:\",len(myList))\nnoOfClasses=len(myList)\nprint(\"Importing Classes.....\")\nfor x in range (0,len(myList)):\n    myPicList = os.listdir(path+\"/\"+str(count))\n    for y in myPicList:\n        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n        img = np.asarray(curImg)\n        img = cv2.resize(img, (60, 60))\n        images.append(img)\n        classNo.append(count)\n    print(count, end =\" \")\n    count +=1\nprint(\" \")\nimages = np.array(images)\nclassNo = np.array(classNo)","metadata":{"_uuid":"47dc3e2b-f4e8-4c9d-894c-efcd531eb5f4","_cell_guid":"9477c2b4-695b-46cd-a958-132ba62b5098","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:01.419087Z","iopub.execute_input":"2022-12-06T08:56:01.420315Z","iopub.status.idle":"2022-12-06T08:56:04.868563Z","shell.execute_reply.started":"2022-12-06T08:56:01.420258Z","shell.execute_reply":"2022-12-06T08:56:04.866564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data, 80% train, 20% test\nX_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=0.2)\nX_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)","metadata":{"_uuid":"8962d963-89a1-456b-b111-08e566273ffe","_cell_guid":"a911cf5a-64d0-4d41-9b7a-2d988ec05100","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:07.877848Z","iopub.execute_input":"2022-12-06T08:56:07.878268Z","iopub.status.idle":"2022-12-06T08:56:07.887703Z","shell.execute_reply.started":"2022-12-06T08:56:07.878234Z","shell.execute_reply":"2022-12-06T08:56:07.885909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict = np.array(predict)\nfor i in range(0,9):\n    plt.subplot(330+i+1)\n    plt.imshow(X_train[i])  \nplt.show()","metadata":{"_uuid":"9efd9b40-a98c-4063-b050-9d8b90d7f4d8","_cell_guid":"794041f7-ca97-48e4-9ec9-9cb87a4983ab","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:12.532717Z","iopub.execute_input":"2022-12-06T08:56:12.533122Z","iopub.status.idle":"2022-12-06T08:56:13.362522Z","shell.execute_reply.started":"2022-12-06T08:56:12.533087Z","shell.execute_reply":"2022-12-06T08:56:13.361782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocessing\ndef grayscale(img):\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    return img\ndef equalize(img):\n    img =cv2.equalizeHist(img)\n    return img\ndef preprocessing(img):\n    img = grayscale(img)     \n    img = equalize(img)     \n    img = img/255            \n    return img\n \nX_train=np.array(list(map(preprocessing,X_train)))\nX_validation=np.array(list(map(preprocessing,X_validation)))\nX_test=np.array(list(map(preprocessing,X_test)))","metadata":{"_uuid":"daf506dc-ccb8-4686-b6e3-9987607453a3","_cell_guid":"1e02d0a5-d000-4e14-909a-0088fba3bc39","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:30.638585Z","iopub.execute_input":"2022-12-06T08:56:30.639007Z","iopub.status.idle":"2022-12-06T08:56:30.664783Z","shell.execute_reply.started":"2022-12-06T08:56:30.638974Z","shell.execute_reply":"2022-12-06T08:56:30.663769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshape data\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\nX_validation=X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\nX_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)","metadata":{"_uuid":"9152c0be-f48a-4334-a092-19c559f08cbb","_cell_guid":"bc9268ae-1119-4c15-a3f9-844e4696acb4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:33.639963Z","iopub.execute_input":"2022-12-06T08:56:33.641777Z","iopub.status.idle":"2022-12-06T08:56:33.649471Z","shell.execute_reply.started":"2022-12-06T08:56:33.641715Z","shell.execute_reply":"2022-12-06T08:56:33.647015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Generator for preprocessing data\ndataGen= ImageDataGenerator(width_shift_range=0.1,\n                            zoom_range=0.2,  \n                            shear_range=0.1,  \n                            rotation_range=10)  \ndataGen.fit(X_train)","metadata":{"_uuid":"5faf9367-34a7-4c81-bf6e-22366d075197","_cell_guid":"682ae28a-85dd-46f0-a088-a7027c41bb34","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:37.557502Z","iopub.execute_input":"2022-12-06T08:56:37.557934Z","iopub.status.idle":"2022-12-06T08:56:37.565165Z","shell.execute_reply.started":"2022-12-06T08:56:37.557903Z","shell.execute_reply":"2022-12-06T08:56:37.563485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert label \ny_train = to_categorical(y_train,noOfClasses)\ny_validation = to_categorical(y_validation,noOfClasses)\ny_test = to_categorical(y_test,noOfClasses)","metadata":{"_uuid":"0c64f369-a2bc-48e0-b26a-9e46da19e174","_cell_guid":"5f2690e5-a9ce-4c2d-8629-5981eba140e0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:41.677405Z","iopub.execute_input":"2022-12-06T08:56:41.677811Z","iopub.status.idle":"2022-12-06T08:56:41.684309Z","shell.execute_reply.started":"2022-12-06T08:56:41.677778Z","shell.execute_reply":"2022-12-06T08:56:41.682768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create model \nno_Of_Filters=64\nsize_of_Filter=(5,5)\n                     \nsize_of_Filter2=(3,3)\nsize_of_pool=(2,2)  \n\nmodel= Sequential()\nmodel.add((Conv2D(64,(5,5),input_shape=(60,60,1),activation='relu')))  \nmodel.add((Conv2D(64, (5,5), activation='relu')))\nmodel.add(MaxPooling2D(pool_size=(2,2))) \n\nmodel.add((Conv2D(32, (3,3),activation='relu')))\nmodel.add((Conv2D(32,(3,3), activation='relu')))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(500,activation='relu'))\nmodel.add(Dropout(0.5)) \nmodel.add(Dense(8,activation='softmax')) \nmodel.summary()","metadata":{"_uuid":"ecdbdd05-d86e-48ff-a767-7429b0094ea5","_cell_guid":"98e25e99-2744-4861-9bf2-59b1ac4262a7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:45.217663Z","iopub.execute_input":"2022-12-06T08:56:45.218031Z","iopub.status.idle":"2022-12-06T08:56:45.305792Z","shell.execute_reply.started":"2022-12-06T08:56:45.218002Z","shell.execute_reply":"2022-12-06T08:56:45.304829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile Model\nmodel.compile(optimizer=RMSprop(),loss='categorical_crossentropy',metrics=['accuracy'])\n# Training model \nhistory=model.fit(dataGen.flow(X_train,y_train,batch_size=10),epochs=10,validation_data=(X_validation,y_validation),shuffle=1)","metadata":{"_uuid":"f2cb291b-320b-4767-bdb4-522213b9c5a4","_cell_guid":"09e0f8c0-f040-47ca-98c5-94a4ed46eca5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:56:50.177035Z","iopub.execute_input":"2022-12-06T08:56:50.178228Z","iopub.status.idle":"2022-12-06T08:58:11.568682Z","shell.execute_reply.started":"2022-12-06T08:56:50.178183Z","shell.execute_reply":"2022-12-06T08:58:11.567917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot\nplt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training','validation'])\nplt.title('loss')\nplt.xlabel('epoch')\nplt.figure(2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['training','validation'])\nplt.title('Acurracy')\nplt.xlabel('epoch')\nplt.show()\nscore =model.evaluate(X_test,y_test,verbose=0)\nprint('Test Score:',score[0])\nprint('Test Accuracy:',score[1])","metadata":{"_uuid":"be22051a-df98-451b-a21b-d66a73ba9ec7","_cell_guid":"dd38f030-ff6a-4bd6-8734-eccc789854d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:58:15.769891Z","iopub.execute_input":"2022-12-06T08:58:15.771266Z","iopub.status.idle":"2022-12-06T08:58:16.650244Z","shell.execute_reply.started":"2022-12-06T08:58:15.771201Z","shell.execute_reply":"2022-12-06T08:58:16.648657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nfrom tensorflow.keras.models import load_model\nmodel.save('emotion.h5')\nmodel_ANN = load_model('/kaggle/input/emotion/emotion.h5')","metadata":{"_uuid":"7b0997a2-436a-40f5-852b-50bf5a2cd518","_cell_guid":"e389995f-fe1a-4f98-9855-7a409c381322","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:58:20.225422Z","iopub.execute_input":"2022-12-06T08:58:20.225775Z","iopub.status.idle":"2022-12-06T08:58:20.485150Z","shell.execute_reply.started":"2022-12-06T08:58:20.225748Z","shell.execute_reply":"2022-12-06T08:58:20.483533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import load_img, img_to_array\n\n# See 9 image in data\nfor i in range(0,9): \n    predict = ['neutral','happy','sad','surprise','fear','sad','anger','fear']\n    predict = np.array(predict)\n    img = img_to_array(X_test[i])\n    img = img.reshape(1,60,60,1)\n    \n    print(img.shape)\n    result = np.argmax(model_ANN.predict(img),axis=-1)\n    predict[result]\n    plt.title(predict[result])\n    plt.subplot(330+i+1)\n    plt.imshow(X_train[i])\nplt.show()","metadata":{"_uuid":"6cf062c6-1f33-49f4-b842-3e1a234619a2","_cell_guid":"ad7753ce-c178-49cf-b2b5-1a90edf3eaba","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T08:58:23.872107Z","iopub.execute_input":"2022-12-06T08:58:23.873413Z","iopub.status.idle":"2022-12-06T08:58:25.309023Z","shell.execute_reply.started":"2022-12-06T08:58:23.873377Z","shell.execute_reply":"2022-12-06T08:58:25.307661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect and Classify objects on picture\ndef xuli(img):\n\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    img = img.astype(np.float64)/255\n    return img\n\ndef get(classNo):\n    if   classNo == 0: return 'Neutral'\n    elif classNo == 1: return 'Happy'\n    elif classNo == 2: return 'Sad'\n    elif classNo == 3: return 'Surprise'\n    elif classNo == 4: return 'Fear'\n    elif classNo == 5: return 'Sad'\n    elif classNo == 6: return 'Anger'\n    elif classNo == 7: return 'Fear'\n\nface_cascade = cv.CascadeClassifier()\nface_cascade.load('/kaggle/input/truong-20144481/haarcascade_frontalface_default.xml')\n\nmodel = load_model('/kaggle/input/emotion/emotion.h5')\nframe = cv.imread('/kaggle/input/fffffffff/tuann.jpg', cv.IMREAD_COLOR)\nframe = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n\nface = face_cascade.detectMultiScale(frame)\ngray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\nfor (x,y,w,h) in face:\n    # cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),1)\n    try:\n        roi = frame[y-int(h/10):y+h+int(h/15),x-int(w/15):x+w+int(h/15)]\n        roi = np.asarray(roi)\n        cv.rectangle(frame, (x,y), (x+w,y+h), (0,255,0),2)\n        \n        \n\n        roi = cv.resize(roi,(60,60))\n        roi = xuli(roi)\n        roi = roi.reshape(1,60,60,1)\n\n\n        predict = ['0','1','2','3','4','5','6','7','8','9','10','11','12']\n        predict = np.array(predict)\n        result = np.argmax(model.predict(roi),axis=-1)\n        # text = predict[result]\n        result = int(result)\n        \n        text = get(result)\n\n        # text = predict[result]\n        text = str(text)\n        if result == 0 or result == 1 or result ==3:\n            cv.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n            cv.rectangle(frame, (x,y-40),(x+w, y), (0,255,0),-2)\n            cv.putText(frame, str(get(result)),(x,y-10), cv.FONT_HERSHEY_COMPLEX, 0.75, (0,0,255),2, cv2.LINE_AA)\n        # cv.putText(frame,text,(x-int(w/10),y-int(h/10)),cv.FONT_HERSHEY_DUPLEX,0.5,(0,0,255),1)\n        else: \n            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,255),2)\n            cv2.rectangle(frame, (x,y-40),(x+w, y), (255,0,255),-2)\n            cv2.putText(frame, str(get(result)),(x,y-10), cv.FONT_HERSHEY_COMPLEX, 0.75, (0,0,0),2, cv2.LINE_AA)\n    except Exception as e:\n        print(str(e))\n\nplt.imshow(frame)\nplt.show()","metadata":{"_uuid":"9cc34f42-d1fc-4b2d-ae89-4e437e72b68f","_cell_guid":"1e15b8a8-c1e6-44cb-aa41-cf264ee115ad","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-12-06T09:05:59.019911Z","iopub.execute_input":"2022-12-06T09:05:59.020345Z","iopub.status.idle":"2022-12-06T09:06:00.530652Z","shell.execute_reply.started":"2022-12-06T09:05:59.020287Z","shell.execute_reply":"2022-12-06T09:06:00.528033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"0ed6f31a-2e36-4570-b18d-8fbddfdc8818","_cell_guid":"964827f5-07bb-4508-ada0-9b8679097af6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}